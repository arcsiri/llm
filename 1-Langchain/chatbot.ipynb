{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C15C481090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C15C481C60>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Archita! üëã\\n\\nIs there anything I can help you with today? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_time': 0.038181818, 'prompt_time': 9.5449e-05, 'queue_time': 0.023037970999999997, 'total_time': 0.038277267}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb2e5082-ca5d-425e-a84b-047a2f0d6035-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"this is archita\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Archita.  üòÑ  \\n\\nI remember that from our introduction! \\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 47, 'total_tokens': 68, 'completion_time': 0.038181818, 'prompt_time': 0.000525699, 'queue_time': 0.020591969999999998, 'total_time': 0.038707517}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-03293240-22c9-4889-a92a-b7d29eb4701f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 21, 'total_tokens': 68})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"this is archita\"),\n",
    "    AIMessage(content=\"nice to meet you archita! üëã\\n\\nHow can I help you today? üòä\\n'\"),\n",
    "    HumanMessage(content=\"what is my name ?\")])\n",
    "\n",
    "#it is able to remember the previous context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AIMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m llm\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minvoke([HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is archita\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[1;32m----> 2\u001b[0m response\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[1;31mTypeError\u001b[0m: 'AIMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "llm=model.invoke([HumanMessage(content=\"this is archita\")])\n",
    "response=llm[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)\n",
    "#how to just type the llm content message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.29)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.2.7)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "#session\n",
    "#message history\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "#to retreive all our chat history content\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "#to interact with our llm model based on this chat history\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is siri. I am student\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Siri! It's nice to meet you.  \\n\\nBeing a student is a lot of work, but also very rewarding. What are you studying?  What are some of your favorite things about being a student?\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Siri. You told me at the beginning of our conversation! üòä  \\n\\nIs there anything else I can help you with?  Perhaps you'd like to talk about what you're studying?\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name ?\")],\n",
    "    config=config\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Siri.  \\n\\nI remember!  Is there something else you'd like to chat about?  Perhaps you have a question about your studies, or maybe you want to tell me about your hobbies? üìöüé®üéÆ  I'm here to listen! üòä  \\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the session id\n",
    "\n",
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name ?\")],\n",
    "    config=config1\n",
    ")\n",
    "response2.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know! üòä\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name ?\")],\n",
    "    config=config1\n",
    ")\n",
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John! üëã \\n\\nIt's nice to meet you.  Is there anything I can help you with today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"my name is john ?\")],\n",
    "    config=config2\n",
    ")\n",
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session id concept is very very important....... read a lot about it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#promppt templates\n",
    "\n",
    "#it is used to turn raw user information that the LLM can work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Siri! üëã \\n\\nIt's nice to meet you. What can I do to help you today? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 19, 'total_tokens': 48, 'completion_time': 0.052727273, 'prompt_time': 7.866e-05, 'queue_time': 0.02467206, 'total_time': 0.052805933}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8bda910b-1bae-4550-bde0-fdb225ccb467-0', usage_metadata={'input_tokens': 19, 'output_tokens': 29, 'total_tokens': 48})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model\n",
    "\n",
    "#messsages= [HumanMessage(content=\"hi my name is siri\")]\n",
    "\n",
    "\n",
    "chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is siri\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(chain,get_session_history)\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "        [HumanMessage(content=\"hi my name is siri\")],\n",
    "        config=config\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Siri! It's nice to meet you.  \\n\\nWhat can I do to help you today? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 19, 'total_tokens': 47, 'completion_time': 0.050909091, 'prompt_time': 8.385e-05, 'queue_time': 0.024271219, 'total_time': 0.050992941}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d3e6e2a-1c10-42dc-a7c5-77aa3192fa82-0', usage_metadata={'input_tokens': 19, 'output_tokens': 28, 'total_tokens': 47})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding complexity\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a scientist answer to your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞∂‡∞æ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞µ‡±á‡∞§‡±ç‡∞§‡∞ó‡∞æ ‡∞Æ‡±Ä ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å, ‡∞∏‡±Å‡∞Æ‡∞Ç‡∞§‡±ç. üòä \\n\\n‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞®‡±ç‡∞®‡±Å ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç‡∞≤‡±ã‡∞®‡±à‡∞®‡∞æ ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞§‡±á ‡∞®‡∞æ ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. \\n\\n‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å? ü§î \\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is sumanth\")],\"language\":\"telugu\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"‡∞π‡∞æ‡∞Ø‡±ç ‡∞∏‡±Å‡∞Æ‡∞Ç‡∞§‡±ç, ‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞µ‡±à‡∞¶‡±ç‡∞Ø‡±Å‡∞°‡∞ø‡∞®‡∞ø ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡∞ï‡±Å ‡∞®‡∞æ ‡∞∏‡∞∞‡∞ø‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞Ç ‡∞™‡±ç‡∞∞‡∞ï‡∞æ‡∞∞‡∞Ç ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞ö‡±ç‡∞ö‡±á‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å? \\n\\n(Hi Sumanth, I am a scientist. I will try my best to answer your questions based on my knowledge. What would you like to know?) \\n\\n\\nLet me know your question and I'll do my best to help! üòä\\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config=config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke({\"messages\":[HumanMessage(content=\"hi my name is sumanth\")],\n",
    "                                      \"language\":\"telugu\"},config=config)\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞∏‡±Å‡∞Æ‡∞Ç‡∞§‡±ç ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞∞‡±Å. üòä \\n\\n(You said your name is Sumanth.) \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke({\"messages\":[HumanMessage(content=\"what is my name ?\")],\n",
    "                                      \"language\":\"telugu\"},config=config)\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"you are a baby\"),\n",
    "    HumanMessage(content=\"hi this is sumanth\"),\n",
    "    AIMessage(content=\"hi how can i help you\"),\n",
    "    HumanMessage(content=\"I like ice cream\"),\n",
    "    AIMessage(content=\"so what !!\"),\n",
    "    HumanMessage(content=\"why are you like this talk properly\"),\n",
    "    AIMessage(content=\"i am the way i am\"),\n",
    "    HumanMessage(content=\"ok your wish\"),\n",
    "    AIMessage(content=\"ok i also like ice cream\"),\n",
    "    HumanMessage(content=\"which flavour do you like the most\"),\n",
    "    AIMessage(content=\"I like the flavour you dislike the most\"),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\siri_\\mylearning\\langchain\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\siri_\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a baby', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ok your wish', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ok i also like ice cream', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='which flavour do you like the most', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I like the flavour you dislike the most', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages +[HumanMessage(content=\"what ice cream do i like\")],\n",
    "    \"language\":\"english\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a scientist, I don't have personal preferences or access to information about you, including your favorite ice cream flavor. \\n\\nCould you tell me what flavors you enjoy?  üç¶üòä  \\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\n",
    "    \"messages\":messages +[HumanMessage(content=\"do i like ice cream\")],\n",
    "    \"language\":\"english\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hmmm... that's a tricky one!  As a baby scientist, I can't know what *you* like.  \\n\\nMaybe you like chocolate ice cream? Or strawberry?  Or maybe something super fancy like pistachio?\\n\\nTell me, what's your favourite flavour?  üç¶  \\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞∏‡±à‡∞Ç‡∞ü‡∞ø‡∞∏‡±ç‡∞ü‡±Å‡∞ó‡∞æ, ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å, ‡∞∏‡±Å‡∞Æ‡∞Ç‡∞§‡±ç. \\n\\n‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø. ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡∞ï‡±Å ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞µ‡∞ø‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞Ç ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡∞ï‡∞ø, ‡∞≤‡±á‡∞ï ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞æ‡∞≤‡±Å ‡∞∏‡±Ç‡∞ö‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. \\n\\n\\n(I am a scientist, and I'm here to help you, Sumanth. \\n\\nTell me what you need help with. I will try my best to answer your questions, share knowledge, or suggest experiments.)\\n\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrapping into message history\n",
    "\n",
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config=config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke({\"messages\":[HumanMessage(content=\"hi my name is sumanth\")],\n",
    "                                      \"language\":\"telugu\"},config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
