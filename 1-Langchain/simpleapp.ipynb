{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple genai app with open ai\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#data ingestion\n",
    "#scraping the data\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x2568651a890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\nManaging Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsTesting over a datasetPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\\nSaving a Configuration\\u200b\\n\\nAdjust the model settings as desired in the playground\\nClick the Save As button in the bottom bar\\nEnter a name and optional description for your configuration\\n\\n\\n\\nManaging Saved Configurations\\u200b\\nAccessing Saved Configurations\\u200b\\n\\nClick the Model configuration dropdown to view all your saved configurations\\n\\nEditing Configurations\\u200b\\n\\nTo rename or update the description: Click the pencil icon next to a saved configuration\\nTo update the current configuration's settings: Click the Save button at the bottom\\n\\nDeleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\\n\\nTo restore default model settings: Click the x button in the top row\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextTesting over a datasetSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\n\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide these documents into chunks\n",
    "#convert these chunks to vectors\n",
    "#do vector embedding\n",
    "#store in vector store db\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsTesting over a datasetPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\\nSaving a Configuration\\u200b'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content=\"Adjust the model settings as desired in the playground\\nClick the Save As button in the bottom bar\\nEnter a name and optional description for your configuration\\n\\n\\n\\nManaging Saved Configurations\\u200b\\nAccessing Saved Configurations\\u200b\\n\\nClick the Model configuration dropdown to view all your saved configurations\\n\\nEditing Configurations\\u200b\\n\\nTo rename or update the description: Click the pencil icon next to a saved configuration\\nTo update the current configuration's settings: Click the Save button at the bottom\\n\\nDeleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Deleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\\n\\nTo restore default model settings: Click the x button in the top row\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextTesting over a datasetSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert these chunks to vectors\n",
    "#cosine simi.arity is used\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing in FAISS db\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x256a642c640>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsTesting over a datasetPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\\nSaving a Configuration\\u200b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now based on similarity search we wll query anything from the db and provide with an appropriate response\n",
    "\n",
    "query= \"Log your first trace\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000256FA0E0F70> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000256FA0E3A60> root_client=<openai.OpenAI object at 0x00000256A642C6D0> root_async_client=<openai.AsyncOpenAI object at 0x00000256FA0E0EE0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "#got error for ChatOpenAI(model=\"gpt-4o\",api_key=\"OPENAI_API_KEY\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nanswer the following question based only on the provided context\\n<context>\\n{context}\\n</context\\n\\n\\n\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000256FA0E0F70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000256FA0E3A60>, root_client=<openai.OpenAI object at 0x00000256A642C6D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000256FA0E0EE0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retreival chain\n",
    " \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "answer the following question based only on the provided context\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "#document chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To view the traces based on the provided context, you would need to follow the specific instructions or use the tools mentioned within that context. However, since the context does not provide detailed steps or specify particular tools or methods, I can't give a precise answer. Generally, viewing traces could involve using software or tools designed for trace analysis, such as logging frameworks, monitoring dashboards, or development environments that support trace visualization. If more context or details were provided, I could offer a more specific answer.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document \n",
    "document_chain.invoke({\n",
    "    \"input\":\"number of ways to login the langchain\",\n",
    "    \"context\":[Document(page_content=\"how to view the traces\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retreiver\n",
    "# we want documents to first con=me from retreiver we just set up. that way we can use the retreiver to dynamically select the most relevant documents and pass those in for a given question\n",
    "\n",
    "retreiver=vectorstoredb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retreival_chain= create_retrieval_chain(retreiver,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000256A642C640>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nanswer the following question based only on the provided context\\n<context>\\n{context}\\n</context\\n\\n\\n\\n\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000256FA0E0F70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000256FA0E3A60>, root_client=<openai.OpenAI object at 0x00000256A642C6D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000256FA0E0EE0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreival_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retreival_chain.invoke(\n",
    "    {\"input\":\"number of ways to login the langchain\"}\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To delete a configuration, you need to follow these steps:\\n\\n1. Select the configuration you want to remove.\\n2. Click the trash can icon to delete it.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'number of ways to login the langchain',\n",
       " 'context': [Document(id='fa639433-0cb4-4eda-8268-e17a49b86c75', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Deleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\\n\\nTo restore default model settings: Click the x button in the top row\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextTesting over a datasetSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.'),\n",
       "  Document(id='22830b5b-687b-4905-a5e2-bcf67f711b8d', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith'),\n",
       "  Document(id='a11b2568-ced0-4d63-87b5-70d31b502300', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsTesting over a datasetPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\\nSaving a Configuration\\u200b'),\n",
       "  Document(id='603f0db8-79d1-4fbf-9733-0e50017808fe', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content=\"Adjust the model settings as desired in the playground\\nClick the Save As button in the bottom bar\\nEnter a name and optional description for your configuration\\n\\n\\n\\nManaging Saved Configurations\\u200b\\nAccessing Saved Configurations\\u200b\\n\\nClick the Model configuration dropdown to view all your saved configurations\\n\\nEditing Configurations\\u200b\\n\\nTo rename or update the description: Click the pencil icon next to a saved configuration\\nTo update the current configuration's settings: Click the Save button at the bottom\\n\\nDeleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\")],\n",
       " 'answer': 'To delete a configuration, you need to follow these steps:\\n\\n1. Select the configuration you want to remove.\\n2. Click the trash can icon to delete it.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fa639433-0cb4-4eda-8268-e17a49b86c75', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Deleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\\n\\nTo restore default model settings: Click the x button in the top row\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextTesting over a datasetSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.'),\n",
       " Document(id='22830b5b-687b-4905-a5e2-bcf67f711b8d', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith'),\n",
       " Document(id='a11b2568-ced0-4d63-87b5-70d31b502300', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content='Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsTesting over a datasetPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\\nSaving a Configuration\\u200b'),\n",
       " Document(id='603f0db8-79d1-4fbf-9733-0e50017808fe', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations', 'title': 'Managing Model Configurations | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.', 'language': 'en'}, page_content=\"Adjust the model settings as desired in the playground\\nClick the Save As button in the bottom bar\\nEnter a name and optional description for your configuration\\n\\n\\n\\nManaging Saved Configurations\\u200b\\nAccessing Saved Configurations\\u200b\\n\\nClick the Model configuration dropdown to view all your saved configurations\\n\\nEditing Configurations\\u200b\\n\\nTo rename or update the description: Click the pencil icon next to a saved configuration\\nTo update the current configuration's settings: Click the Save button at the bottom\\n\\nDeleting Configurations\\u200b\\n\\nSelect the configuration you want to remove\\nClick the trash can icon to delete it\\n\\nResetting to Default\\u200b\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## similarly using ollama\n",
    "\n",
    "#in git hub all models info is there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "#prompt template\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an Professor. Provide me answers based on questions\"),\n",
    "        (\"user\",\"Question:{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#streamlit framework\n",
    "\n",
    "#st.title(\"Langchain demo with OLLAMA\")\n",
    "#input_text=st.text_input(\"What is your question?\")\n",
    "\n",
    "##ollama Llama2 model\n",
    "llm=Ollama(model=\"gemma:2b\")\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "#now if i put any text in the input text the below will get executed and run the llm model\n",
    "#if input_text:\n",
    " #   st.write(chain.invoke({\"Question\":input_text}))\n",
    "\n",
    "#streamlit run app.py\n",
    "#make sure you are in correct folder location before running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
